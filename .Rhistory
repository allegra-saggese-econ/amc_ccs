filename <- paste0("orbis_long_", date_str, ".csv")
write.csv(orbis_final2, filename, row.names = FALSE)
numeric_cols <- orbis_final2 %>%
select(where(is.numeric))
# Calculate percentage of NAs and non-NAs
na_summary <- data.frame(
column_name = colnames(numeric_cols),
percent_na = colMeans(is.na(numeric_cols)) * 100
) %>%
mutate(percent_non_na = 100 - percent_na)
# View the summary table
print(na_summary)
write_csv(na_summary, "output/numeric_column_na_summary.csv")
write_csv(na_summary, "numeric_column_na_summary.csv")
cwd()
pwd()
getwd()
numeric_cols <- setdiff(
names(orbis_final2)[sapply(orbis_final2, is.numeric)],
c("Year")
)
# Calculate % NA and % non-NA by Year and Column
na_by_year <- orbis_final2 %>%
select(Year, all_of(numeric_cols)) %>%
pivot_longer(-Year, names_to = "column_name", values_to = "value") %>%
group_by(Year, column_name) %>%
summarise(
percent_na = mean(is.na(value)) * 100,
percent_non_na = 100 - percent_na,
.groups = "drop"
)
# View the result
print(na_by_year)
write_csv(na_by_year, "numeric_na_summary_by_year.csv")
# Import patent<>firm matched data
##### needs formatting work
patent_data <- read_csv(file.path(projdir, "clean_outputs/did_df.csv"))
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(readr)
# Define project directory based on username
username <- Sys.getenv("USER")  # or use "ignaciobanaressanchez", "ibanares", "BANARESS" for testing
if (username == "ignaciobanaressanchez") {
projdir <- "/Users/ignaciobanaressanchez/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "ibanares") {
projdir <- "/Users/ibanares/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "BANARESS") {
projdir <- "C:/Users/BANARESS/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "allegrasaggese") {
projdir <- "/Users/allegrasaggese/Documents/GitHub/amc_ccs/"
}
# Import Orbis data
orbis_data <- read_csv(file.path(projdir, "data/orbis/orbis_gen_1.csv"))
projdir
# Import Orbis data - updated with clean data
orbis_data <- read_csv(file.path(projdir, "clean_outputs/orbis_long_2025-06-26.csv"))
#' Author: [Allegra Saggese]
#' Purpose: Convert SDID code from STATA to R (provided by Ignacio)
#' Last updated: `r format(Sys.Date(), "%Y-%m-%d")`
# Load necessary libraries
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(readr)
# Define project directory based on username
username <- Sys.getenv("USER")  # or use "ignaciobanaressanchez", "ibanares", "BANARESS" for testing
if (username == "ignaciobanaressanchez") {
projdir <- "/Users/ignaciobanaressanchez/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "ibanares") {
projdir <- "/Users/ibanares/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "BANARESS") {
projdir <- "C:/Users/BANARESS/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "allegrasaggese") {
projdir <- "/Users/allegrasaggese/Documents/GitHub/amc_ccs/"
}
# Import Orbis data - updated with clean data
orbis_data <- read_csv(file.path(projdir, "clean_outputs/orbis_long_2025-06-26.csv"))
# Import patent<>firm matched data
patent_data <- read_csv(file.path(projdir, "clean_outputs/did_df.csv"))
# Import patent<>firm matched data (do from scratch - take OG dataset)
patent_data <- read_csv(file.path(projdir, "clean_outputs/firm_level_data.csv"))
View(patent_data)
# Import patent<>firm matched data (do from scratch - take OG dataset)
patent_data_raw <- read_csv(file.path(projdir, "clean_outputs/firm_level_data.csv"))
# Import cleaned version of patent <> firm matched data
patent_data_clean <- read_csv(file.path(projdir, "clean_outputs/did_df_copy.csv"))
#' Author: [Allegra Saggese]
#' Purpose: Convert SDID code from STATA to R (provided by Ignacio)
#' Last updated: `r format(Sys.Date(), "%Y-%m-%d")`
# Load necessary libraries
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(readr)
# Define project directory based on username
username <- Sys.getenv("USER")  # or use "ignaciobanaressanchez", "ibanares", "BANARESS" for testing
if (username == "ignaciobanaressanchez") {
projdir <- "/Users/ignaciobanaressanchez/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "ibanares") {
projdir <- "/Users/ibanares/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "BANARESS") {
projdir <- "C:/Users/BANARESS/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "allegrasaggese") {
projdir <- "/Users/allegrasaggese/Documents/GitHub/amc_ccs/"
}
# Import Orbis data - updated with clean data
orbis_data <- read_csv(file.path(projdir, "clean_outputs/orbis_long_2025-06-26.csv"))
# Import patent<>firm matched data (do from scratch - take OG dataset)
patent_data_raw <- read_csv(file.path(projdir, "clean_outputs/firm_level_data.csv"))
# Import cleaned version of patent <> firm matched data
patent_data_clean <- read_csv(file.path(projdir, "clean_outputs/did_df_copy.csv"))
orbis_data <- read_csv(file.path(projdir, "clean_outputs/orbis_long_2025-06-26.csv"))
patent_data_raw <- read_csv(file.path(projdir, "clean_outputs/firm_level_data.csv"))
View(patent_data_raw)
patent_data_clean <- read_csv(file.path(projdir, "clean_outputs/did_df_copy.csv"))
View(patent_data_clean)
View(orbis_data)
# before we merge orbis to patent data -- make orbis data month-year
months_df <- tibble(Month = 1:12)
months_df <- tibble(Month = 1:12)
orbis_month <- orbis_data %>%
tidyr::crossing(months_df) %>%
arrange(firm_name, Year, Month)
View(orbis_month)
# View result
head(df_firm_year_month, 20)
head(orbis_month, 20)
class(patent_data_clean$m_y)
orbis_month <- orbis_month %>%
mutate(
m_y = format(as.Date(paste(Year, Month, "01", sep = "-")), "%b %Y")
)
head(orbis_month$m_y)
fdf <- left_merge(orbis_data, patent_data_clean, by = c("m_y, firm_name"))
# Merge orbis and clean patent data
fdf <- full_join(orbis_data, patent_data_clean, by = c("m_y, firm_name"))
# Merge orbis and clean patent data
fdf <- full_join(orbis_month, patent_data_clean, by = c("m_y, firm_name"))
# Merge orbis and clean patent data
fdf <- full_join(orbis_month, patent_data_clean, by = c("m_y, firm_name"))
colnames(patent_data_clean)
colnames(orbis_month)
patent_f <- patent_data_clean %>%
mutate(firm_name = substr(key, 1, nchar(key) - 5))
View(patent_f)
# check firm names in both datasets for consistency -- pull out unique names
names_1 <- unique(patent_f$firm_name)
names_2 <- unique(orbis_month$firm_name)
only_in_df1 <- setdiff(names_1, names_2)
only_in_df2 <- setdiff(names_2, names_1)
comparison_result <- list(
only_in_df1 = only_in_df1,
only_in_df2 = only_in_df2
)
View(comparison_result)
only_in_df1
only_in_df2
common_names <- intersect(names_1, names_2)
common_names <- intersect(tolower(names_1), tolower(names_2))
# Load necessary libraries
install.packages("stringdist")
rm(orbis_data, patent_data_raw)
# Load necessary libraries
library(stringdist)
names_1 <- unique(tolower(patent_f$firm_name)) # refill with lowercase names from both dfs
names_2 <- unique(tolower(orbis_month$firm_name))
dist_matrix <- stringdistmatrix(names_1, names_2, method = "jw") # distance calc
View(dist_matrix)
min_match_indices <- apply(dist_matrix, 1, which.min)
closest_matches <- names_2[min_match_indices]
fuzzy_matches <- data.frame(
original = names_1,
matched = closest_matches,
distance = mapply(function(i, j) dist_matrix[i, j], seq_along(min_match_indices), min_match_indices)
)
View(fuzzy_matches)
names_2
View(orbis_month)
orbis_month$firm_name_clean <- str_to_lower(orbis_month$firm_name) %>%
str_remove_all("\\b(ltd|llc|inc\\.?|co\\.?|corp\\.?|limited|corporation)\\b") %>%
str_squish()
View(orbis_month)
head(orbis_month$firm_name_clean)
unique(orbis_month$firm_name_clean)
orbis_month$firm_name_clean <- str_to_lower(orbis_month$firm_name) %>%
str_remove_all("\\b(ltd|llc|inc\\.?|co\\.?|corp\\.?|limited|corporation)\\b") %>%
str_remove_all("[\\.,]") %>%  # remove dots and commas
str_squish()
unique(orbis_month$firm_name_clean)
# step 3 - use FUZZY MATCH
names_1 <- unique(tolower(patent_f$firm_name)) # refill with lowercase names from both dfs
names_2 <- unique(orbis_month$firm_name_clean)
dist_matrix <- stringdistmatrix(names_1, names_2, method = "jw") # distance calc
min_match_indices <- apply(dist_matrix, 1, which.min)
closest_matches <- names_2[min_match_indices]
# Combine into a data.frame for inspection
fuzzy_matches <- data.frame(
original = names_1,
matched = closest_matches,
distance = mapply(function(i, j) dist_matrix[i, j], seq_along(min_match_indices), min_match_indices)
)
View(fuzzy_matches)
names_2
names_1
sort(names_2)
sort(names_1)
man_nomatch_vector <- c("alkali earth", "andes", "arbon", "bio-concrete (vtt and puro.earth)",
"biomass burial (ebs and puro.earth)", "bluesource", "breadtree farms",
"carboncapture", "carbonrun", "carbonto stone", "carbotura",
"clairity", "climate foundation marine permaculture", "co2 rail",
"co2-zero", "e-quester", "ensyn biochar", "finnish log house industry",
"first gigaton", "future forest", "graphyte", "holy grail", "hyrogas sia",
"maia paebbl", "mati", "methane oxidation corp", "minerali", "noble thermodynamics",
"nori", "nuestark", "out of the blue", "repair", "rewind earth", "rizomeco",
"silicate", "solid carbon", "susewi", "thermodynamic geoengineering",
"travertine tech", "vaulted")
man_nomatch_vector
patent_f$firm_name
patent_f$firm_name["Captura"]
patent_f$firm_name["captura"]
patent_f$firm_name["captura group"]
patent_f$firm_name[captura group]
patent_f$firm_name = "Captura"
View(patent_f)
ibrary(stringdist)
library(stringdist)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(readr)
# Define project directory based on username
username <- Sys.getenv("USER")  # or use "ignaciobanaressanchez", "ibanares", "BANARESS" for testing
if (username == "ignaciobanaressanchez") {
projdir <- "/Users/ignaciobanaressanchez/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "ibanares") {
projdir <- "/Users/ibanares/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "BANARESS") {
projdir <- "C:/Users/BANARESS/LSE Energy Dropbox/Ignacio Banares/Projects/AMCs"
} else if (username == "allegrasaggese") {
projdir <- "/Users/allegrasaggese/Documents/GitHub/amc_ccs/"
}
####### IMPORT DATA SETS ################
# Import Orbis data - updated with clean data
orbis_data <- read_csv(file.path(projdir, "clean_outputs/orbis_long_2025-06-26.csv"))
# Import patent<>firm matched data (do from scratch - take OG dataset)
patent_data_raw <- read_csv(file.path(projdir, "clean_outputs/firm_level_data.csv")) # does not include treatment variavble
# Import cleaned version of patent <> firm matched data
patent_data_clean <- read_csv(file.path(projdir, "clean_outputs/did_df_copy.csv"))
# before we merge orbis to patent data -- make orbis data month-year
months_df <- tibble(Month = 1:12)
orbis_month <- orbis_data %>%
tidyr::crossing(months_df) %>%
arrange(firm_name, Year, Month)
head(orbis_month, 20)
orbis_month <- orbis_month %>%
mutate(
m_y = format(as.Date(paste(Year, Month, "01", sep = "-")), "%b %Y")
)
# extract out firm name in patent_data_clean
patent_f <- patent_data_clean %>%
mutate(firm_name = substr(key, 1, nchar(key) - 5))
############ FIRM NAME MATCH #################
# WILL NEED TO CLEAN UP BOTH SETS OF NAMES HERE for a fuzzy match
# step 1 - review the existing matches
names_1 <- unique(patent_f$firm_name) # check to see if there are any clear matches
names_2 <- unique(orbis_month$firm_name)
only_in_df1 <- setdiff(names_1, names_2)
only_in_df2 <- setdiff(names_2, names_1)
comparison_result <- list(
only_in_df1 = only_in_df1,
only_in_df2 = only_in_df2
)
common_names <- intersect(names_1, names_2) # no common names - need to ignore case!
# ignoring case theres only two that match perfectly
common_names <- intersect(tolower(names_1), tolower(names_2))
# step 2 - drop the endings of the firm name (LLC, INC, etc.) from the orbis data
orbis_month$firm_name_clean <- str_to_lower(orbis_month$firm_name) %>%
str_remove_all("\\b(ltd|llc|inc\\.?|co\\.?|corp\\.?|limited|corporation)\\b") %>%
str_remove_all("[\\.,]") %>%  # remove dots and commas
str_squish()
# step 3 - use FUZZY MATCH
names_1 <- unique(tolower(patent_f$firm_name)) # refill with lowercase names from both dfs
names_2 <- unique(orbis_month$firm_name_clean)
dist_matrix <- stringdistmatrix(names_1, names_2, method = "jw") # distance calc
min_match_indices <- apply(dist_matrix, 1, which.min)
closest_matches <- names_2[min_match_indices]
fuzzy_matches <- data.frame(
original = names_1,
matched = closest_matches,
distance = mapply(function(i, j) dist_matrix[i, j], seq_along(min_match_indices), min_match_indices)
)
# View top fuzzy matches
fuzzy_matches <- fuzzy_matches[order(fuzzy_matches$distance), ]
head(fuzzy_matches, 20)
sort(names_1)
unique(patent_f$firm_name)
sort(names_1)
sort(names_2)
View(fuzzy_matches)
patent_f_n <- patent_f %>%
tolower(firm_name) %>%
mutate(firm_name = case_when(
firm_name == "captura" ~ "captura group",
firm_name == "carba" ~ "carba - srl",
firm_name == "carbyon" ~ "carbyon holding bv",
firm_name == "living carbon" ~ "living carbon pbc which will do business in california as living carbon",
TRUE ~ firm_name
))
patent_f_n <- patent_f %>%
mutate(firm_name = case_when(
firm_name == "captura" ~ "captura group",
firm_name == "carba" ~ "carba - srl",
firm_name == "carbyon" ~ "carbyon holding bv",
firm_name == "living carbon" ~ "living carbon pbc which will do business in california as living carbon",
TRUE ~ firm_name
))
patent_f_n <- patent_f_n %>%
mutate(firm_name = tolower(firm_name))
View(patent_f_n)
# ignore 40 mismatched (create new vector to skip through in match)
man_nomatch_vector <- c("alkali earth", "andes", "arbon", "bio-concrete (vtt and puro.earth)",
"biomass burial (ebs and puro.earth)", "bluesource", "breadtree farms",
"carboncapture", "carbonrun", "carbonto stone", "carbotura",
"clairity", "climate foundation marine permaculture", "co2 rail",
"co2-zero", "e-quester", "ensyn biochar", "finnish log house industry",
"first gigaton", "future forest", "graphyte", "holy grail", "hyrogas sia",
"maia paebbl", "mati", "methane oxidation corp", "minerali", "noble thermodynamics",
"nori", "nuestark", "out of the blue", "repair", "rewind earth", "rizomeco",
"silicate", "solid carbon", "susewi", "thermodynamic geoengineering",
"travertine tech", "vaulted")
library(fuzzyjoin)
install.packages("fuzzyjoin")
library(fuzzyjoin)
orbis_month_n <- orbis_month %>%
mutate(firm_name = tolower(firm_name))
rm(orbis_month, patent_f)
df1_nomatch <- patent_f_n %>%
filter(firm_name %in% man_nomatch_vector)
View(df1_nomatch)
df1_to_match <- patent_f_n %>%
filter(!firm_name %in% man_nomatch_vector)
View(fuzzy_matches)
fuzzy_matched <- stringdist_join(
df1_to_match, orbis_month_n,
by = "firm_name",
method = "jw",                # Jaro-Winkler match
max_dist = 0.3,              # tweak threshold as needed
distance_col = "dist",
mode = "left"
)
View(fuzzy_matched)
View(fuzzy_matched)
rm(fuzzy_matched)
fuzzy_matched <- df1_to_match %>%
inner_join(orbis_month_n, by = "m_y") %>%  # regular join on m_y
mutate(dist = stringdist::stringdist(firm_name.x, firm_name.y, method = "jw")) %>%
filter(dist <= 0.35) %>%
group_by(firm_name.x, m_y) %>%
slice_min(dist, n = 1) %>%       # optional: keep only best match
ungroup()
View(fuzzy_matched)
# join first on date then closest match
fuzzy_matched <- df1_to_match %>%
inner_join(orbis_month_n, by = "m_y") %>%  # regular join on m_y
mutate(dist = stringdist::stringdist(firm_name.x, firm_name.y, method = "jw")) %>%
filter(dist <= 0.35) %>%
group_by(firm_name.x, m_y) %>%
slice_min(dist, n = 1) %>%
matched_df <- bind_rows(fuzzy_matched, df1_nomatch)
####### IMPORT DATA SETS ################
# Import Orbis data - updated with clean data
orbis_data <- read_csv(file.path(projdir, "clean_outputs/orbis_long_2025-06-26.csv"))
# Import patent<>firm matched data (do from scratch - take OG dataset)
patent_data_raw <- read_csv(file.path(projdir, "clean_outputs/firm_level_data.csv")) # does not include treatment variavble
# Import cleaned version of patent <> firm matched data
patent_data_clean <- read_csv(file.path(projdir, "clean_outputs/did_df_copy.csv"))
# before we merge orbis to patent data -- make orbis data month-year
months_df <- tibble(Month = 1:12)
orbis_month <- orbis_data %>%
tidyr::crossing(months_df) %>%
arrange(firm_name, Year, Month)
head(orbis_month, 20)
orbis_month <- orbis_month %>%
mutate(
m_y = format(as.Date(paste(Year, Month, "01", sep = "-")), "%b %Y")
)
# extract out firm name in patent_data_clean
patent_f <- patent_data_clean %>%
mutate(firm_name = substr(key, 1, nchar(key) - 5))
############ FIRM NAME MATCH #################
# WILL NEED TO CLEAN UP BOTH SETS OF NAMES HERE for a fuzzy match
# step 1 - review the existing matches
names_1 <- unique(patent_f$firm_name) # check to see if there are any clear matches
names_2 <- unique(orbis_month$firm_name)
only_in_df1 <- setdiff(names_1, names_2)
only_in_df2 <- setdiff(names_2, names_1)
comparison_result <- list(
only_in_df1 = only_in_df1,
only_in_df2 = only_in_df2
)
common_names <- intersect(names_1, names_2) # no common names - need to ignore case!
# ignoring case theres only two that match perfectly
common_names <- intersect(tolower(names_1), tolower(names_2))
# step 2 - drop the endings of the firm name (LLC, INC, etc.) from the orbis data
orbis_month$firm_name_clean <- str_to_lower(orbis_month$firm_name) %>%
str_remove_all("\\b(ltd|llc|inc\\.?|co\\.?|corp\\.?|limited|corporation)\\b") %>%
str_remove_all("[\\.,]") %>%  # remove dots and commas
str_squish()
# step 3 - use FUZZY MATCH
names_1 <- unique(tolower(patent_f$firm_name)) # refill with lowercase names from both dfs
names_2 <- unique(orbis_month$firm_name_clean)
dist_matrix <- stringdistmatrix(names_1, names_2, method = "jw") # distance calc
min_match_indices <- apply(dist_matrix, 1, which.min)
closest_matches <- names_2[min_match_indices]
# Combine into a data.frame for inspection
fuzzy_matches <- data.frame(
original = names_1,
matched = closest_matches,
distance = mapply(function(i, j) dist_matrix[i, j], seq_along(min_match_indices), min_match_indices)
)
# review matches
fuzzy_matches <- fuzzy_matches[order(fuzzy_matches$distance), ]
head(fuzzy_matches, 20)
# with manual review we have 4 mismatch and 40 no match
# manual override of mismatch by manual change to names
patent_f_n <- patent_f %>%
mutate(firm_name = case_when(
firm_name == "captura" ~ "captura group",
firm_name == "carba" ~ "carba - srl",
firm_name == "carbyon" ~ "carbyon holding bv",
firm_name == "living carbon" ~ "living carbon pbc which will do business in california as living carbon",
TRUE ~ firm_name
))
# make both lower case
patent_f_n <- patent_f_n %>%
mutate(firm_name = tolower(firm_name))
orbis_month_n <- orbis_month %>%
mutate(firm_name = tolower(firm_name))
# ignore 40 mismatched (create new vector to skip through in match)
man_nomatch_vector <- c("alkali earth", "andes", "arbon", "bio-concrete (vtt and puro.earth)",
"biomass burial (ebs and puro.earth)", "bluesource", "breadtree farms",
"carboncapture", "carbonrun", "carbonto stone", "carbotura",
"clairity", "climate foundation marine permaculture", "co2 rail",
"co2-zero", "e-quester", "ensyn biochar", "finnish log house industry",
"first gigaton", "future forest", "graphyte", "holy grail", "hyrogas sia",
"maia paebbl", "mati", "methane oxidation corp", "minerali", "noble thermodynamics",
"nori", "nuestark", "out of the blue", "repair", "rewind earth", "rizomeco",
"silicate", "solid carbon", "susewi", "thermodynamic geoengineering",
"travertine tech", "vaulted")
# Merge orbis and clean patent data
df1_nomatch <- patent_f_n %>%
filter(firm_name %in% man_nomatch_vector)
df1_to_match <- patent_f_n %>%
filter(!firm_name %in% man_nomatch_vector)
# join first on date then closest match
fuzzy_matched <- df1_to_match %>%
inner_join(orbis_month_n, by = "m_y") %>%  # regular join on m_y
mutate(dist = stringdist::stringdist(firm_name.x, firm_name.y, method = "jw")) %>%
filter(dist <= 0.35) %>%
group_by(firm_name.x, m_y) %>%
slice_min(dist, n = 1) %>%
ungroup()
#row bind unmatched firms
final_df <- bind_rows(fuzzy_matched, df1_nomatch)
View(final_df)
colnames(final_df)
df_v1 <- final_df %>%
mutate(patent_filed = 1)
ggplot(df_v1 , aes(x = m_y, y = patents_in_period)) +
geom_line() +
scale_x_continuous(breaks = seq(564, 764, by = 10)) +
labs(x = "", y = "Sum of Applicants' Patents") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
ggsave(filename = file.path(projdir, "output/sum_patents.pdf"))
prjdir
projdir
ggplot(df_v1 , aes(x = m_y, y = patents_in_period)) +
geom_line() +
scale_x_continuous(breaks = seq(564, 764, by = 10)) +
labs(x = "", y = "Sum of Applicants' Patents") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
ggsave(filename = file.path(projdir, "/graphs_output/2025_sum_patent_vis.pdf"))
ggplot(df_v1 , aes(x = m_y, y = patents_in_period)) +
geom_line() +
scale_x_continuous(breaks = seq(564, 764, by = 10)) +
labs(x = "", y = "Sum of Applicants' Patents") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
rlang::last_trace()
final_df$m_y_date <- as.Date(paste0("01 ", final_df$m_y), format = "%d %b %Y")
ggplot(final_df , aes(x = m_y, y = patents_in_period)) +
geom_line() +
scale_x_continuous(breaks = seq(564, 764, by = 10)) +
labs(x = "", y = "Sum of Applicants' Patents") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(final_df , aes(x = m_y_date, y = patents_in_period)) +
geom_line() +
scale_x_continuous(breaks = seq(564, 764, by = 10)) +
labs(x = "", y = "Sum of Applicants' Patents") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(final_df , aes(x = m_y_date, y = patents_in_period)) +
geom_line() +
scale_x_continuous(breaks = seq(564, 764, by = 10)) +
labs(x = "", y = "Sum of Applicants' Patents") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
write_csv(final_df, file.path(projdir, "/clean_outputs/250701_patent_firm_orbis.csv")
write_csv(final_df, file.path(projdir, "/clean_outputs/250701_patent_firm_orbis.csv"))
write_csv(final_df, file.path(projdir, "clean_outputs", "250701_patent_firm_orbis.csv"))
